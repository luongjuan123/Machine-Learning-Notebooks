{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d289acc-52ef-4aad-a62d-d9b926e2455e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcadf3b-4c34-4cff-8265-379ea68a5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_intercept(x):\n",
    "    \"\"\"Add intercept to matrix x.\n",
    "\n",
    "    Args:\n",
    "        x: 2D NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        New matrix same as x with 1's in the 0th column.\n",
    "    \"\"\"\n",
    "    new_x = np.zeros((x.shape[0], x.shape[1] + 1), dtype=x.dtype)\n",
    "    new_x[:, 0] = 1\n",
    "    new_x[:, 1:] = x\n",
    "\n",
    "    return new_x\n",
    "\n",
    "\n",
    "def load_dataset(csv_path, label_col='y', add_intercept=False):\n",
    "    \"\"\"Load dataset from a CSV file.\n",
    "\n",
    "    Args:\n",
    "         csv_path: Path to CSV file containing dataset.\n",
    "         label_col: Name of column to use as labels (should be 'y' or 'l').\n",
    "         add_intercept: Add an intercept entry to x-values.\n",
    "\n",
    "    Returns:\n",
    "        xs: Numpy array of x-values (inputs).\n",
    "        ys: Numpy array of y-values (labels).\n",
    "    \"\"\"\n",
    "\n",
    "    def add_intercept_fn(x):\n",
    "        global add_intercept\n",
    "        return add_intercept(x)\n",
    "\n",
    "    # Validate label_col argument\n",
    "    allowed_label_cols = ('y', 't')\n",
    "    if label_col not in allowed_label_cols:\n",
    "        raise ValueError('Invalid label_col: {} (expected {})'\n",
    "                         .format(label_col, allowed_label_cols))\n",
    "\n",
    "    # Load headers\n",
    "    with open(csv_path, 'r') as csv_fh:\n",
    "        headers = csv_fh.readline().strip().split(',')\n",
    "\n",
    "    # Load features and labels\n",
    "    x_cols = [i for i in range(len(headers)) if headers[i].startswith('x')]\n",
    "    l_cols = [i for i in range(len(headers)) if headers[i] == label_col]\n",
    "    inputs = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=x_cols)\n",
    "    labels = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=l_cols)\n",
    "\n",
    "    if inputs.ndim == 1:\n",
    "        inputs = np.expand_dims(inputs, -1)\n",
    "\n",
    "    if add_intercept:\n",
    "        inputs = add_intercept_fn(inputs)\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "def plot(x, y, theta, save_path=None, correction=1.0):\n",
    "    \"\"\"Plot dataset and fitted logistic regression parameters.\n",
    "    Args:\n",
    "        x: Matrix of training examples, one per row.\n",
    "        y: Vector of labels in {0, 1}.\n",
    "        theta: Vector of parameters for logistic regression model.\n",
    "        save_path: Path to save the plot.\n",
    "        correction: Correction factor to apply (Problem 2(e) only).\n",
    "    \"\"\"\n",
    "    # Plot dataset\n",
    "    plt.figure()\n",
    "    plt.plot(x[y == 1, -2], x[y == 1, -1], 'bx', linewidth=2)\n",
    "    plt.plot(x[y == 0, -2], x[y == 0, -1], 'go', linewidth=2)\n",
    "\n",
    "    # Plot decision boundary (found by solving for theta^T x = 0)\n",
    "    margin1 = (max(x[:, -2]) - min(x[:, -2]))*0.2\n",
    "    margin2 = (max(x[:, -1]) - min(x[:, -1]))*0.2\n",
    "    x1 = np.arange(min(x[:, -2])-margin1, max(x[:, -2])+margin1, 0.01)\n",
    "    x2 = -(theta[0] / theta[2] * correction + theta[1] / theta[2] * x1)\n",
    "    plt.plot(x1, x2, c='red', linewidth=2)\n",
    "    plt.xlim(x[:, -2].min()-margin1, x[:, -2].max()+margin1)\n",
    "    plt.ylim(x[:, -1].min()-margin2, x[:, -1].max()+margin2)\n",
    "\n",
    "    # Add labels and save to disk\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefe367-11d8-435e-9c3a-0ec03aa41813",
   "metadata": {},
   "source": [
    "# **Linear Regression**\n",
    "\n",
    "---\n",
    "\n",
    "## **Loss (Cost) Function**\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2m} \n",
    "\\sum_{i=1}^{m} \\left( h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}) - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Hypothesis Function**\n",
    "\n",
    "$$\n",
    "h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}) = \n",
    "\\boldsymbol{\\theta}^\\top \\mathbf{x}^{(i)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Notation Summary**\n",
    "\n",
    "| Symbol | Meaning |\n",
    "|:--:|:--|\n",
    "| $m$ | number of training examples |\n",
    "| $\\mathbf{x}^{(i)}$ | input feature vector of the $i^{th}$ example |\n",
    "| $y^{(i)}$ | true label for the $i^{th}$ example |\n",
    "| $\\boldsymbol{\\theta}$ | parameter (weight) vector |\n",
    "| $h_{\\boldsymbol{\\theta}}(x)$ | predicted value (hypothesis) |\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ’¡ *Goal:* Find parameters $\\boldsymbol{\\theta}$ that minimize the cost function $J(\\boldsymbol{\\theta})$, i.e.  \n",
    "$$\n",
    "\\boldsymbol{\\theta}^* = \\arg\\min_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c408a3aa-2e0a-4fdb-96c2-4005d430fd7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LinearModel(object):\n",
    "    \"\"\"Base class for linear models\"\"\"\n",
    "    def __init__(self, step_size, max_iter=100, eps=1e-6,\n",
    "                theta_0=None, verbose=True):\n",
    "        \n",
    "        self.theta = theta_0\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(X, y):\n",
    "        \"\"\"Run solver so fit linear model.\n",
    "        \n",
    "        Args:\n",
    "            X: Training example inputs. Shape (m, n)\n",
    "            y: Training example labels. Shape (m, )\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Subclass of LinearModel must implement fit method.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"Make a pediction given new inputs x\n",
    "        Args:\n",
    "            X: Input of shape(m, n)\n",
    "        \n",
    "        Returns:\n",
    "            Output of shape(m, )\"\"\"\n",
    "\n",
    "        raise NotImplemetedError(\"Subclass of LinearModel must implement predict method.\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de0dd5-12b4-41c3-bfa9-662a7d267b6b",
   "metadata": {},
   "source": [
    "# **1. Batch Gradient Descent(BGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80a74da-efa0-4fa4-b28a-8e49db0c5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegessionBatchGradientDescent(LinearModel):\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.theta = np.zeros(n)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            theta_old = np.copy(self.theta)\n",
    "            \n",
    "            # Compute gradient\n",
    "            gradient = (1/(2*m)) * (X @ self.theta - y) @ X\n",
    "            \n",
    "            # Update parameters\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "            \n",
    "            # Check convergence\n",
    "            if np.linalg.norm(self.theta - theta_old, ord=1) < self.eps:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.theta\n",
    "        \n",
    "def main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40391e3-7676-48bd-8fad-03adda4448a2",
   "metadata": {},
   "source": [
    "# **2. Stochatic Gradient Descent(BGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282f22fe-c421-49fe-a22a-59c425669aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionStochaticGradientDescent(LinearModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape()\n",
    "\n",
    "        #Initialize parameters\n",
    "        self.theta = np.zeros(n)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            theta_old = np.copy(self.theta)\n",
    "\n",
    "            # Shuffle data each epoch\n",
    "            indices = np.random.permutation(m)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            # Update weights per sample\n",
    "            for i in range(m):\n",
    "                xi = X_shuffled[i:i+1]          # shape (1, n)\n",
    "                yi = y_shuffled[i]\n",
    "                gradient = 1/2 * (xi @ self.theta - yi) @ xi\n",
    "                self.theta -= self.learning_rate * gradient.flatten()\n",
    "\n",
    "            # Early stopping if change small\n",
    "            if np.linalg.norm(self.theta - theta_old, ord=1) < self.tol:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.theta        \n",
    "\n",
    "def main():\n",
    "    pass        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc7761-1653-4288-9440-d5bf97f60114",
   "metadata": {},
   "source": [
    "# **3. Normal Equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989aca5e-1df8-4806-aa06-04e18fe49d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionNormalEquation(LinearModel):\n",
    "    def fit(self, X, y):\n",
    "        # Normal equation: Î¸ = (Xáµ€X)â»Â¹ Xáµ€y\n",
    "        self.theta = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.theta\n",
    "def main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c2045-758a-4a4b-b2c4-bf9bc283a720",
   "metadata": {},
   "source": [
    "# **4. Locally Weighted Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ae0c51-2d8f-4370-9e35-353fd2010b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocallyWeightedLinearRegression:\n",
    "    def __init__(self, tau):\n",
    "        self.tau = tau\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data.\"\"\"\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions given inputs X.\n",
    "        \n",
    "        Args:\n",
    "            X: shape (m, n)\n",
    "        Returns:\n",
    "            y_pred: shape (m,)\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        y_pred = np.zeros(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            # compute weights for each training sample relative to query X[i]\n",
    "            diff = self.x - X[i]                     # (m, n)\n",
    "            W = np.diag(np.exp(-np.sum(diff**2, axis=1) / (2 * self.tau**2)))\n",
    "\n",
    "            # solve for theta = (X^T W X)^(-1) X^T W y\n",
    "            A = self.x.T @ W @ self.x\n",
    "            b = self.x.T @ W @ self.y\n",
    "            # regularization for stability\n",
    "            theta = np.linalg.solve(A + 1e-5 * np.eye(n), b)\n",
    "\n",
    "            # predict y_hat = x_i^T theta\n",
    "            y_pred[i] = X[i] @ theta\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9643403-8c84-4c6f-8e76-29036c5c9c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
