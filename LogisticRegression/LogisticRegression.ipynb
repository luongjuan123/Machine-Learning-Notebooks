{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e7198f-89af-4da4-b42f-f960c7cb11cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Util**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aff239-9f9a-4428-beab-9f9520868f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class util(object):\n",
    "    @staticmethod\n",
    "    def add_intercept(x):\n",
    "        \"\"\"Add intercept to matrix x.\n",
    "\n",
    "        Args:\n",
    "            x: 2D NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            New matrix same as x with 1's in the 0th column.\n",
    "        \"\"\"\n",
    "        new_x = np.zeros((x.shape[0], x.shape[1] + 1), dtype=x.dtype)\n",
    "        new_x[:, 0] = 1\n",
    "        new_x[:, 1:] = x\n",
    "        return new_x\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(csv_path, label_col='y', add_intercept=False):\n",
    "        \"\"\"Load dataset from a CSV file.\n",
    "\n",
    "        Args:\n",
    "            csv_path: Path to CSV file containing dataset.\n",
    "            label_col: Name of column to use as labels (should be 'y' or 't').\n",
    "            add_intercept: Add an intercept entry to x-values.\n",
    "\n",
    "        Returns:\n",
    "            xs: Numpy array of x-values (inputs).\n",
    "            ys: Numpy array of y-values (labels).\n",
    "        \"\"\"\n",
    "        # Validate label_col argument\n",
    "        allowed_label_cols = ('y', 't')\n",
    "        if label_col not in allowed_label_cols:\n",
    "            raise ValueError(\n",
    "                f'Invalid label_col: {label_col} (expected one of {allowed_label_cols})'\n",
    "            )\n",
    "\n",
    "        # Load headers\n",
    "        with open(csv_path, 'r') as csv_fh:\n",
    "            headers = csv_fh.readline().strip().split(',')\n",
    "\n",
    "        # Load features and labels\n",
    "        x_cols = [i for i in range(len(headers)) if headers[i].startswith('x')]\n",
    "        l_cols = [i for i in range(len(headers)) if headers[i] == label_col]\n",
    "        inputs = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=x_cols)\n",
    "        labels = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=l_cols)\n",
    "\n",
    "        if inputs.ndim == 1:\n",
    "            inputs = np.expand_dims(inputs, -1)\n",
    "\n",
    "        if add_intercept:\n",
    "            inputs = util.add_intercept(inputs)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def plot(x, y, theta, save_path=None, correction=1.0):\n",
    "        \"\"\"Plot dataset and fitted logistic regression parameters.\n",
    "\n",
    "        Args:\n",
    "            x: Matrix of training examples, one per row.\n",
    "            y: Vector of labels in {0, 1}.\n",
    "            theta: Vector of parameters for logistic regression model.\n",
    "            save_path: Path to save the plot.\n",
    "            correction: Correction factor to apply (Problem 2(e) only).\n",
    "        \"\"\"\n",
    "        # Plot dataset\n",
    "        plt.figure()\n",
    "        plt.plot(x[y == 1, -2], x[y == 1, -1], 'bx', linewidth=2)\n",
    "        plt.plot(x[y == 0, -2], x[y == 0, -1], 'go', linewidth=2)\n",
    "\n",
    "        # Plot decision boundary (found by solving for theta^T x = 0)\n",
    "        margin1 = (max(x[:, -2]) - min(x[:, -2])) * 0.2\n",
    "        margin2 = (max(x[:, -1]) - min(x[:, -1])) * 0.2\n",
    "        x1 = np.arange(min(x[:, -2]) - margin1, max(x[:, -2]) + margin1, 0.01)\n",
    "        x2 = -(theta[0] / theta[2] * correction + theta[1] / theta[2] * x1)\n",
    "        plt.plot(x1, x2, c='red', linewidth=2)\n",
    "        plt.xlim(x[:, -2].min() - margin1, x[:, -2].max() + margin1)\n",
    "        plt.ylim(x[:, -1].min() - margin2, x[:, -1].max() + margin2)\n",
    "\n",
    "        # Add labels and save to disk\n",
    "        plt.xlabel('x1')\n",
    "        plt.ylabel('x2')\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959eed6b-9c9f-4a32-9c61-df1312ddec60",
   "metadata": {},
   "source": [
    "# **Logistic Regression**\n",
    "\n",
    "---\n",
    "\n",
    "## **Loss (Cost) Function**\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \n",
    "- \\frac{1}{m} \\sum_{i=1}^{m} \n",
    "\\Big[ \n",
    "y^{(i)} \\log\\big(h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})\\big) \n",
    "+ \\big(1 - y^{(i)}\\big) \\log\\big(1 - h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})\\big)\n",
    "\\Big]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Hypothesis Function**\n",
    "\n",
    "$$\n",
    "h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}) \n",
    "= \\sigma\\big(\\boldsymbol{\\theta}^\\top \\mathbf{x}^{(i)}\\big)\n",
    "$$\n",
    "\n",
    "where the **sigmoid function** is:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Notation Summary**\n",
    "\n",
    "| Symbol | Meaning |\n",
    "|:--:|:--|\n",
    "| $m$ | number of training examples |\n",
    "| $\\mathbf{x}^{(i)}$ | input feature vector of the $i^{th}$ example |\n",
    "| $y^{(i)} \\in \\{0, 1\\}$ | true label for the $i^{th}$ example |\n",
    "| $\\boldsymbol{\\theta}$ | parameter (weight) vector |\n",
    "| $h_{\\boldsymbol{\\theta}}(x)$ | predicted probability that $y=1$ |\n",
    "| $\\sigma(z)$ | sigmoid activation function |\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ’¡ *Goal:* Find parameters $\\boldsymbol{\\theta}$ that minimize the cost function $J(\\boldsymbol{\\theta})$, i.e.  \n",
    "$$\n",
    "\\boldsymbol{\\theta}^* = \\arg\\min_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c618b1c-7284-4210-b6f0-785413a36d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01ffead-43ea-43ec-965c-8445d635e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(object):\n",
    "    \"\"\"Base class for linear models\"\"\"\n",
    "    def __init__(self, step_size, max_iter=100, eps=-1e6,\n",
    "                theta_0=None, verbose=True):\n",
    "        \n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.theta_0 = theta_0\n",
    "        self.verbose = verbose\n",
    "    def fit(X, y):\n",
    "        \"\"\"Run solver so fit linear model.\n",
    "        \n",
    "        Args:\n",
    "            X: Training example inputs. Shape (m, n)\n",
    "            y: Training example labels. Shape (m, )\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Subclass of LinearModel must implement fit method.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"Make a pediction given new inputs x\n",
    "        Args:\n",
    "            X: Input of shape(m, n)\n",
    "        \n",
    "        Returns:\n",
    "            Output of shape(m, )\"\"\"\n",
    "\n",
    "        raise NotImplemetedError(\"Subclass of LinearModel must implement predict method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1261e-21d2-4f17-99d0-91f75d0f4908",
   "metadata": {},
   "source": [
    "# **1. Bacth Gradient Descent Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dab2e9e-0ed2-40d7-85d9-ae3dfd10e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGradientDescentLogisticRegression(LinearModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)\n",
    "\n",
    "        while True:\n",
    "            theta_old = np.copy(self.theta)\n",
    "            h = sigmoid(X @ self.theta)\n",
    "            gradient = X.T @ (h - y) / m             \n",
    "            self.theta -= self.step_size * gradient     \n",
    "            \n",
    "            if np.linalg.norm(self.theta - theta_old, ord=1) < self.eps:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        return sigmoid(X @ self.theta)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295026f5-0fcb-4a6b-8e8d-8fb3f341b821",
   "metadata": {},
   "source": [
    "# **2. Stochatic Gradient Descent Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b134b690-0d8e-4bcb-b4cb-4273865e40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochaticGradientDescentLogisticRegression(LinearModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            indices = np.random.permutation(m)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            theta_old = np.copy(self.theta)\n",
    "\n",
    "            for i in range(m):\n",
    "                xi = X_shuffled[i].reshape(-1, 1)\n",
    "                yi = y_shuffled[i]\n",
    "                hi = float(xi.T @ self.theta)     \n",
    "                gradient = (hi - yi) * xi          \n",
    "                self.theta -= self.step_size * gradient\n",
    "\n",
    "            if np.linalg.norm(self.theta - theta_old, ord=1) < self.eps:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        return sigmoid(X @ self.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1a33b-cd66-4a98-942e-d2c5f25d8577",
   "metadata": {},
   "source": [
    "# **3. Newton's Method Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656f9c3-3f90-4816-83f7-52961696f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewtonMethodLogisticRegression(LinearModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
